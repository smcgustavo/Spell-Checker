{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0fb3d0b9394885e8da6cbf98fbf949c86e2ceadbdfb51251ea6d36f9091f0c647",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Corretor Ortográfico"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Importando bibliotecas e carregando arquivos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/quasares/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "source": [
    "### Abrindo e salvando o arquivo de texto"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artigos.txt', 'r') as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "source": [
    "### Funções usadas no código:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleciona_palavra(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_caracter(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def troca_caracter(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverte_caracter(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += remove_caracter(fatias)\n",
    "    palavras_geradas += troca_caracter(fatias)\n",
    "    palavras_geradas += inverte_caracter(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra_errada):\n",
    "    palavras_geradas = gerador_palavras(palavra_errada)\n",
    "    palavras_corretas = max(palavras_geradas, key = probabilidade)\n",
    "    return palavras_corretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, 'r')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(teste):\n",
    "    numero_palavras = len(teste)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for certa, errada in teste:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (certa not in vocabulario)\n",
    "        if palavra_corrigida == certa:\n",
    "            acertou += 1   \n",
    "    taxa_de_acerto = acertou/numero_palavras\n",
    "    taxa_desconhecida = desconhecida/numero_palavras\n",
    "    print('Taxa de acerto de {}% de {} palavras.'.format(round(taxa_de_acerto * 100, 2), numero_palavras))\n",
    "    print('Taxa de palavras desconhecidas {}%.'.format(round(taxa_desconhecida * 100, 2)))"
   ]
  },
  {
   "source": [
    "### Tratamento da lista de palavras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização de palavras:\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de caracteres que são palavras:\n",
    "lista_palavras = seleciona_palavra(lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deixando todas as palavras com caracteres minúsculos\n",
    "lista_normalizada = normalizacao(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis importantes\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "teste = cria_dados_teste('palavras.txt')\n",
    "vocabulario = set(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Taxa de acerto de 76.34% de 186 palavras.\nTaxa de palavras desconhecidas 6.99%.\n"
     ]
    }
   ],
   "source": [
    "avaliador(teste)"
   ]
  }
 ]
}